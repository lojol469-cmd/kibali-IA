# ğŸ‹ Guide Docker - Kibali IA v2.0

## ğŸ“‹ Structure Docker

```
kibali-IA/
â”œâ”€â”€ Dockerfile              # Image Docker avec PyTorch 2.10 + CUDA 13.0
â”œâ”€â”€ docker-compose.yml      # Orchestration Docker Compose
â”œâ”€â”€ docker-build.sh         # Script de build automatique
â”œâ”€â”€ .dockerignore          # Fichiers Ã  exclure du build
â””â”€â”€ .env                   # Variables d'environnement (API keys)
```

## ğŸš€ Utilisation

### Option 1: Script automatique (RecommandÃ©)

```bash
# Build de l'image
./docker-build.sh

# Lancer avec docker-compose
docker-compose up -d

# Voir les logs
docker-compose logs -f

# ArrÃªter
docker-compose down
```

### Option 2: Docker Compose manuel

```bash
# Build et dÃ©marrage
docker-compose up -d --build

# ArrÃªt
docker-compose down

# Voir les logs
docker-compose logs -f kibali-ia
```

### Option 3: Docker run direct

**Avec GPU (NVIDIA):**
```bash
docker run -d \
  --name kibali-ia \
  --gpus all \
  -p 8501:8501 \
  -v $(pwd)/kibali_data:/app/kibali_data \
  -v $(pwd)/.env:/app/.env:ro \
  kibali-ia:2.0-streaming
```

**Avec CPU (fallback automatique):**
```bash
docker run -d \
  --name kibali-ia \
  -p 8501:8501 \
  -v $(pwd)/kibali_data:/app/kibali_data \
  -v $(pwd)/.env:/app/.env:ro \
  kibali-ia:2.0-streaming
```

## ğŸ“¦ Configuration

### Variables d'environnement (.env)

```env
HF_TOKEN=hf_your_huggingface_token
TAVILY_API_KEY=your_tavily_api_key
```

### Volumes Docker

| Volume hÃ´te | Volume container | Description |
|-------------|------------------|-------------|
| `./kibali_data/pdfs` | `/app/kibali_data/pdfs` | Documents PDF |
| `./kibali_data/graphs` | `/app/kibali_data/graphs` | Graphes OSM |
| `./kibali_data/vectordb` | `/app/kibali_data/vectordb` | Base vectorielle |
| `./kibali_data/models` | `/app/kibali_data/models` | ModÃ¨les locaux |
| `./outputs` | `/app/outputs` | Fichiers gÃ©nÃ©rÃ©s |

## ğŸ® Support GPU

L'image supporte automatiquement :
- âœ… **NVIDIA GPU** : CUDA 13.0 (RTX 5090 compatible)
- âœ… **CPU Fallback** : DÃ©tection automatique

### PrÃ©requis GPU

1. **NVIDIA Docker Runtime:**
```bash
# Installer nvidia-docker2
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

2. **Tester:**
```bash
docker run --rm --gpus all nvidia/cuda:13.0.0-base-ubuntu22.04 nvidia-smi
```

## ğŸ“Š Commandes utiles

```bash
# Voir les conteneurs
docker ps

# Logs en temps rÃ©el
docker logs -f kibali-ia

# Entrer dans le conteneur
docker exec -it kibali-ia bash

# Statistiques ressources
docker stats kibali-ia

# Reconstruire sans cache
docker-compose build --no-cache

# Nettoyer
docker system prune -a
```

## ğŸ”§ DÃ©pannage

### ProblÃ¨me: "CUDA not available"
**Solution:** VÃ©rifier NVIDIA Docker:
```bash
docker run --rm --gpus all nvidia/cuda:13.0.0-base-ubuntu22.04 nvidia-smi
```

### ProblÃ¨me: "Permission denied .env"
**Solution:** VÃ©rifier les permissions:
```bash
chmod 644 .env
```

### ProblÃ¨me: Port 8501 dÃ©jÃ  utilisÃ©
**Solution:** Changer le port dans docker-compose.yml:
```yaml
ports:
  - "8502:8501"  # Utiliser 8502 Ã  la place
```

### ProblÃ¨me: Espace disque insuffisant
**Solution:** Nettoyer Docker:
```bash
docker system prune -a --volumes
```

## ğŸ—ï¸ Architecture de l'image

```
Base: nvidia/cuda:13.0.0-cudnn9-runtime-ubuntu22.04
â”œâ”€â”€ Python 3.13
â”œâ”€â”€ PyTorch 2.10 (nightly) + CUDA 13.0
â”œâ”€â”€ Kibali IA v2.0
â”‚   â”œâ”€â”€ Streaming token activÃ©
â”‚   â”œâ”€â”€ Fallback CPU automatique
â”‚   â””â”€â”€ Licences commerciales OK
â””â”€â”€ DÃ©pendances:
    â”œâ”€â”€ Streamlit, LangChain, Transformers
    â”œâ”€â”€ pdfplumber (MIT), OpenCV, CLIP
    â””â”€â”€ FAISS, Sentence-Transformers
```

## ğŸ“ˆ Performance

**Taille de l'image:** ~8-10 GB (avec PyTorch + CUDA)

**MÃ©moire requise:**
- CPU: 4 GB minimum, 8 GB recommandÃ©
- GPU: 8 GB VRAM minimum, 16+ GB recommandÃ©

**Build time:** ~15-30 minutes (premiÃ¨re fois)

## ğŸŒ Production

### Docker Hub (pousser l'image)

```bash
# Tag
docker tag kibali-ia:2.0-streaming yourusername/kibali-ia:2.0

# Push
docker push yourusername/kibali-ia:2.0
```

### Kubernetes (exemple)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibali-ia
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibali-ia
  template:
    metadata:
      labels:
        app: kibali-ia
    spec:
      containers:
      - name: kibali-ia
        image: kibali-ia:2.0-streaming
        ports:
        - containerPort: 8501
        resources:
          limits:
            nvidia.com/gpu: 1
```

## âœ… Checklist avant build

- [ ] Fichier `.env` configurÃ© avec les API keys
- [ ] NVIDIA Docker installÃ© (pour GPU)
- [ ] Espace disque suffisant (20+ GB)
- [ ] Port 8501 disponible
- [ ] Connexion internet (tÃ©lÃ©chargement PyTorch)

## ğŸ“ Notes

- L'image utilise **PyTorch 2.10 nightly** pour supporter RTX 5090
- Le **fallback CPU** est automatique si pas de GPU
- Les **modÃ¨les locaux** ne sont pas inclus (trop volumineux)
- Utiliser des **volumes** pour la persistance des donnÃ©es

---

**Version:** 2.0 Streaming Edition  
**Date:** 7 dÃ©cembre 2025  
**Support:** GPU NVIDIA + CPU fallback
