"""
Classificateur intelligent de photos pour photogramm√©trie
Utilise Vision AI (CLIP) pour analyser et ordonner les photos par similarit√© visuelle
"""
import numpy as np
import cv2
from pathlib import Path
from typing import List, Dict, Tuple
import torch
from PIL import Image

class IntelligentPhotoClassifier:
    """
    Classe pour classifier intelligemment les photos de photogramm√©trie
    en analysant les textures, d√©tails visuels et angles de vue avec l'IA
    """
    
    def __init__(self, clip_model, clip_processor, device='cuda'):
        self.clip_model = clip_model
        self.clip_processor = clip_processor
        self.device = device
        
    def extract_visual_features(self, image_path: str) -> Dict:
        """
        Extrait les features visuelles d'une image avec CLIP + analyse d√©taill√©e
        
        Returns:
            Dict avec:
            - clip_embedding: Vecteur CLIP (512 dim)
            - texture_features: Analyse de texture
            - color_histogram: Distribution des couleurs
            - edge_density: Densit√© de contours
            - brightness: Luminosit√© moyenne
            - contrast: Contraste
        """
        # Charger l'image
        image = Image.open(image_path).convert('RGB')
        img_cv = cv2.imread(str(image_path))
        
        # 1. CLIP Embedding (compr√©hension s√©mantique)
        with torch.no_grad():
            inputs = self.clip_processor(images=image, return_tensors="pt").to(self.device)
            clip_features = self.clip_model.get_image_features(**inputs)
            clip_embedding = clip_features.cpu().numpy().flatten()
        
        # 2. Analyse de texture (gradients)
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)
        gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)
        
        texture_features = {
            'mean': gradient_magnitude.mean(),
            'std': gradient_magnitude.std(),
            'max': gradient_magnitude.max(),
            'p25': np.percentile(gradient_magnitude, 25),
            'p75': np.percentile(gradient_magnitude, 75)
        }
        
        # 3. Histogramme couleur (distribution RGB)
        color_histogram = []
        for i in range(3):
            hist = cv2.calcHist([img_cv], [i], None, [32], [0, 256])
            hist = hist.flatten() / (hist.sum() + 1e-5)
            color_histogram.extend(hist.tolist())
        
        # 4. Densit√© de contours (Canny)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = edges.sum() / (edges.shape[0] * edges.shape[1])
        
        # 5. Luminosit√© et contraste
        brightness = gray.mean()
        contrast = gray.std()
        
        # 6. Features ORB (points cl√©s pour matching)
        orb = cv2.ORB_create(nfeatures=100)
        keypoints, descriptors = orb.detectAndCompute(gray, None)
        
        orb_features = {
            'num_keypoints': len(keypoints),
            'keypoint_response': np.mean([kp.response for kp in keypoints]) if keypoints else 0.0
        }
        
        return {
            'clip_embedding': clip_embedding,
            'texture': texture_features,
            'color_histogram': np.array(color_histogram),
            'edge_density': edge_density,
            'brightness': brightness,
            'contrast': contrast,
            'orb': orb_features,
            'image_shape': img_cv.shape
        }
    
    def compute_visual_similarity(self, features1: Dict, features2: Dict) -> float:
        """
        Calcule la similarit√© visuelle entre deux images
        
        Returns:
            Score de similarit√© (0.0 √† 1.0)
            - 1.0 = tr√®s similaires (angles proches)
            - 0.0 = tr√®s diff√©rentes
        """
        # 1. Similarit√© CLIP (s√©mantique) - poids 50%
        clip_sim = np.dot(features1['clip_embedding'], features2['clip_embedding'])
        clip_sim = (clip_sim + 1) / 2  # Normaliser de [-1,1] √† [0,1]
        
        # 2. Similarit√© de texture - poids 20%
        texture_diff = 0
        for key in ['mean', 'std', 'p25', 'p75']:
            t1 = features1['texture'][key]
            t2 = features2['texture'][key]
            texture_diff += abs(t1 - t2) / (max(t1, t2) + 1e-5)
        texture_sim = 1.0 - (texture_diff / 4.0)
        
        # 3. Similarit√© couleur (histogramme) - poids 15%
        hist1 = features1['color_histogram']
        hist2 = features2['color_histogram']
        color_sim = 1.0 - np.sum(np.abs(hist1 - hist2)) / 2.0
        
        # 4. Similarit√© de luminosit√©/contraste - poids 10%
        brightness_diff = abs(features1['brightness'] - features2['brightness']) / 255.0
        contrast_diff = abs(features1['contrast'] - features2['contrast']) / 100.0
        lighting_sim = 1.0 - (brightness_diff + contrast_diff) / 2.0
        
        # 5. Similarit√© de contours - poids 5%
        edge_diff = abs(features1['edge_density'] - features2['edge_density'])
        edge_sim = 1.0 - edge_diff
        
        # Score final pond√©r√©
        final_similarity = (
            0.50 * clip_sim +
            0.20 * texture_sim +
            0.15 * color_sim +
            0.10 * lighting_sim +
            0.05 * edge_sim
        )
        
        return np.clip(final_similarity, 0.0, 1.0)
    
    def classify_and_order_photos(
        self, 
        photo_paths: List[str],
        method: str = 'sequential'
    ) -> Tuple[List[str], Dict]:
        """
        Classifie et ordonne les photos pour reconstruction 3D optimale
        
        Args:
            photo_paths: Liste des chemins d'images
            method: 'sequential' (ordre s√©quentiel) ou 'cluster' (par groupes)
        
        Returns:
            - Liste ordonn√©e des chemins
            - Dictionnaire avec statistiques et analyse
        """
        print(f"üîç Analyse de {len(photo_paths)} photos avec Vision AI...")
        
        # 1. Extraire features pour toutes les images
        features_list = []
        for idx, path in enumerate(photo_paths):
            print(f"   üì∏ Analyse {idx+1}/{len(photo_paths)}: {Path(path).name}")
            features = self.extract_visual_features(path)
            features['path'] = path
            features['index'] = idx
            features_list.append(features)
        
        print(f"‚úÖ Features extraites pour {len(features_list)} images")
        
        # 2. Calculer matrice de similarit√©
        n = len(features_list)
        similarity_matrix = np.zeros((n, n))
        
        print("üîó Calcul des similarit√©s entre images...")
        for i in range(n):
            for j in range(i+1, n):
                sim = self.compute_visual_similarity(features_list[i], features_list[j])
                similarity_matrix[i][j] = sim
                similarity_matrix[j][i] = sim
        
        print("‚úÖ Matrice de similarit√© calcul√©e")
        
        # 3. Ordonner selon la m√©thode choisie
        if method == 'sequential':
            ordered_indices = self._order_sequential(similarity_matrix, features_list)
            order_type = "S√©quentiel (photos qui se suivent)"
        else:
            ordered_indices = self._order_by_clusters(similarity_matrix, features_list)
            order_type = "Par groupes d'angles similaires"
        
        # 4. Cr√©er la liste ordonn√©e
        ordered_paths = [features_list[idx]['path'] for idx in ordered_indices]
        
        # 5. Calculer statistiques
        stats = self._compute_statistics(similarity_matrix, ordered_indices, features_list)
        stats['order_type'] = order_type
        stats['total_photos'] = len(photo_paths)
        
        return ordered_paths, stats
    
    def _order_sequential(self, similarity_matrix: np.ndarray, features_list: List[Dict]) -> List[int]:
        """
        Ordonne les photos de mani√®re s√©quentielle (cha√Æne de similarit√©)
        Algorithme: Nearest Neighbor Chain
        """
        n = len(features_list)
        visited = [False] * n
        ordered = []
        
        # Commencer par l'image avec la luminosit√© moyenne (ni trop sombre, ni trop claire)
        brightnesses = [f['brightness'] for f in features_list]
        median_brightness = np.median(brightnesses)
        current = np.argmin([abs(b - median_brightness) for b in brightnesses])
        
        ordered.append(current)
        visited[current] = True
        
        # Construire la cha√Æne
        for _ in range(n - 1):
            # Trouver l'image non visit√©e la plus similaire
            similarities = similarity_matrix[current].copy()
            similarities[visited] = -1  # Exclure les visit√©es
            
            next_idx = np.argmax(similarities)
            ordered.append(next_idx)
            visited[next_idx] = True
            current = next_idx
        
        return ordered
    
    def _order_by_clusters(self, similarity_matrix: np.ndarray, features_list: List[Dict]) -> List[int]:
        """
        Ordonne les photos par groupes d'angles similaires
        """
        from sklearn.cluster import AgglomerativeClustering
        
        n = len(features_list)
        
        # Convertir similarit√© en distance
        distance_matrix = 1.0 - similarity_matrix
        
        # Clustering hi√©rarchique
        n_clusters = max(3, min(10, n // 5))  # Entre 3 et 10 clusters
        clustering = AgglomerativeClustering(
            n_clusters=n_clusters,
            metric='precomputed',
            linkage='average'
        )
        labels = clustering.fit_predict(distance_matrix)
        
        # Ordonner par cluster, puis par similarit√© dans chaque cluster
        ordered = []
        for cluster_id in range(n_clusters):
            cluster_indices = [i for i in range(n) if labels[i] == cluster_id]
            
            # Trier par luminosit√© dans le cluster (progression naturelle)
            cluster_indices.sort(key=lambda i: features_list[i]['brightness'])
            ordered.extend(cluster_indices)
        
        return ordered
    
    def _compute_statistics(
        self, 
        similarity_matrix: np.ndarray, 
        ordered_indices: List[int],
        features_list: List[Dict]
    ) -> Dict:
        """Calcule des statistiques sur l'ordonnancement"""
        
        # Similarit√© moyenne entre images cons√©cutives
        consecutive_similarities = []
        for i in range(len(ordered_indices) - 1):
            idx1 = ordered_indices[i]
            idx2 = ordered_indices[i + 1]
            consecutive_similarities.append(similarity_matrix[idx1][idx2])
        
        avg_consecutive_sim = np.mean(consecutive_similarities) if consecutive_similarities else 0
        
        # Diversit√© de la couverture (variance des embeddings CLIP)
        embeddings = np.array([features_list[i]['clip_embedding'] for i in ordered_indices])
        coverage_variance = np.var(embeddings)
        
        # Distribution de luminosit√©
        brightnesses = [features_list[i]['brightness'] for i in ordered_indices]
        
        return {
            'avg_consecutive_similarity': float(avg_consecutive_sim),
            'min_consecutive_similarity': float(min(consecutive_similarities)) if consecutive_similarities else 0,
            'max_consecutive_similarity': float(max(consecutive_similarities)) if consecutive_similarities else 0,
            'coverage_variance': float(coverage_variance),
            'brightness_range': (float(min(brightnesses)), float(max(brightnesses))),
            'brightness_progression': 'smooth' if np.std(np.diff(brightnesses)) < 20 else 'varied'
        }
    
    def visualize_ordering(
        self, 
        photo_paths: List[str], 
        ordered_paths: List[str],
        output_dir: str
    ):
        """
        Cr√©e une visualisation de l'ordonnancement avec miniatures
        """
        import matplotlib.pyplot as plt
        from matplotlib.gridspec import GridSpec
        
        n = len(ordered_paths)
        cols = min(10, n)
        rows = (n + cols - 1) // cols
        
        fig = plt.figure(figsize=(cols * 2, rows * 2))
        gs = GridSpec(rows, cols, figure=fig, hspace=0.3, wspace=0.1)
        
        for idx, path in enumerate(ordered_paths):
            row = idx // cols
            col = idx % cols
            
            ax = fig.add_subplot(gs[row, col])
            
            # Charger et afficher miniature
            img = Image.open(path)
            img.thumbnail((200, 200))
            ax.imshow(img)
            ax.axis('off')
            ax.set_title(f"#{idx+1}", fontsize=8)
        
        plt.suptitle(f"Ordre des {n} photos pour reconstruction 3D", fontsize=16, fontweight='bold')
        
        output_path = Path(output_dir) / "photo_ordering_visualization.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return str(output_path)
    
    def generate_report(
        self, 
        ordered_paths: List[str], 
        stats: Dict,
        output_dir: str
    ) -> str:
        """G√©n√®re un rapport d√©taill√© de la classification"""
        
        report = []
        report.append("=" * 70)
        report.append("üì∑ RAPPORT DE CLASSIFICATION INTELLIGENTE - PHOTOGRAMM√âTRIE")
        report.append("=" * 70)
        report.append("")
        
        report.append(f"üìä **Statistiques globales:**")
        report.append(f"   Nombre total de photos: {stats['total_photos']}")
        report.append(f"   M√©thode d'ordonnancement: {stats['order_type']}")
        report.append("")
        
        report.append(f"üîó **Coh√©rence de l'ordre:**")
        report.append(f"   Similarit√© moyenne (photos cons√©cutives): {stats['avg_consecutive_similarity']*100:.1f}%")
        report.append(f"   Similarit√© minimale: {stats['min_consecutive_similarity']*100:.1f}%")
        report.append(f"   Similarit√© maximale: {stats['max_consecutive_similarity']*100:.1f}%")
        report.append("")
        
        report.append(f"üé® **Analyse de couverture:**")
        report.append(f"   Variance de couverture: {stats['coverage_variance']:.4f}")
        report.append(f"   Plage de luminosit√©: {stats['brightness_range'][0]:.1f} - {stats['brightness_range'][1]:.1f}")
        report.append(f"   Progression: {stats['brightness_progression']}")
        report.append("")
        
        report.append(f"‚úÖ **Qualit√© de l'ordonnancement:**")
        if stats['avg_consecutive_similarity'] > 0.75:
            report.append(f"   ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê EXCELLENT - Photos tr√®s bien ordonn√©es")
        elif stats['avg_consecutive_similarity'] > 0.60:
            report.append(f"   ‚≠ê‚≠ê‚≠ê‚≠ê BON - Ordre coh√©rent pour reconstruction")
        elif stats['avg_consecutive_similarity'] > 0.45:
            report.append(f"   ‚≠ê‚≠ê‚≠ê ACCEPTABLE - Peut n√©cessiter ajustements")
        else:
            report.append(f"   ‚≠ê‚≠ê MOYEN - Photos tr√®s diff√©rentes")
        
        report.append("")
        report.append("=" * 70)
        report.append("")
        report.append(f"üìã **Ordre des photos (optimis√© pour Dust3R/reconstruction 3D):**")
        report.append("")
        
        for idx, path in enumerate(ordered_paths, 1):
            filename = Path(path).name
            report.append(f"   {idx:3d}. {filename}")
        
        report.append("")
        report.append("=" * 70)
        report.append("üí° **Recommandations:**")
        report.append("   - Utilisez cet ordre pour Dust3R, MeshRoom ou autres outils 3D")
        report.append("   - Les photos sont class√©es par similarit√© d'angles de vue")
        report.append("   - La progression est optimis√©e pour une reconstruction fluide")
        report.append("=" * 70)
        
        report_text = "\n".join(report)
        
        # Sauvegarder le rapport
        report_path = Path(output_dir) / "classification_report.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        return report_text


def classify_photos_with_ai(
    photo_paths: List[str],
    clip_model,
    clip_processor,
    device: str = 'cuda',
    method: str = 'sequential',
    output_dir: str = None
) -> Tuple[List[str], str, str]:
    """
    Fonction principale pour classifier des photos avec l'IA
    
    Returns:
        - ordered_paths: Liste ordonn√©e des chemins
        - report: Rapport textuel
        - visualization_path: Chemin de la visualisation
    """
    classifier = IntelligentPhotoClassifier(clip_model, clip_processor, device)
    
    # Classifier et ordonner
    ordered_paths, stats = classifier.classify_and_order_photos(photo_paths, method=method)
    
    # G√©n√©rer rapport
    if output_dir:
        report = classifier.generate_report(ordered_paths, stats, output_dir)
        
        # Cr√©er visualisation
        try:
            viz_path = classifier.visualize_ordering(photo_paths, ordered_paths, output_dir)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur visualisation: {e}")
            viz_path = None
    else:
        report = f"Photos ordonn√©es: {len(ordered_paths)} images"
        viz_path = None
    
    return ordered_paths, report, viz_path
